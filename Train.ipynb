{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c182b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run MCTS.ipynb\n",
    "%run NNet_architecture.ipynb\n",
    "%run Deck.ipynb\n",
    "%run Board.ipynb\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9426e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "# model = load_model(\"models/latest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_board = Board(deck)\n",
    "root = MonteCarloTreeSearchNode(model, new_board, prior=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241c79a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7c73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model_name, nb_simulations):\n",
    "    \n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_board_states.pickle', 'rb') as handle:\n",
    "        board_states = pickle.load(handle)\n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_policies.pickle', 'rb') as handle:\n",
    "        policies = pickle.load(handle)\n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_values.pickle', 'rb') as handle:\n",
    "        values = pickle.load(handle)\n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_nb_games.pickle', 'rb') as handle:\n",
    "        nb_games = pickle.load(handle)\n",
    "            \n",
    "    return board_states, policies, values, nb_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_play(model, model_name, root, nb_simulations=200, nb_games=2, max_move_per_game=np.inf):\n",
    "    \n",
    "    games = [MonteCarloTreeSearchNode(model, Board(deck), prior=0) for i in range(nb_games)]\n",
    "    game = 0\n",
    "    i = 0\n",
    "    board_states = []\n",
    "    values = []\n",
    "    policies = []\n",
    "    \n",
    "    while game < nb_games:\n",
    "        node = games[game]\n",
    "        i = 0\n",
    "        while not node.board.is_game_over() and i < max_move_per_game:\n",
    "            node.simulate(nb_simulations)\n",
    "\n",
    "            l = [(ind, node._number_of_visits) for ind, node in node.children.items()]\n",
    "            ind, action = max(l, key = lambda x:x[1])\n",
    "\n",
    "            policy = np.zeros(5 * 5 * 52)\n",
    "            total_visits = sum([b._number_of_visits for b in node.children.values()])\n",
    "            for a, b in node.children.items():\n",
    "                policy[a] = b._number_of_visits/total_visits\n",
    "\n",
    "            policies.append(policy)\n",
    "            board_states.append(node.board.board_state)\n",
    "            values.append(node.mean_value()[0][0])\n",
    "\n",
    "            # nodes.append(node)\n",
    "            node = node.children[ind]\n",
    "\n",
    "            plt.imshow(node.board.board_2D)\n",
    "            plt.show()\n",
    "            i += 1\n",
    "            print(\"-----------\", i)\n",
    "        game +=1\n",
    "        print(\"-----------------------------------------\", game, \"-----------------------------------------\")\n",
    "\n",
    "    if not os.path.exists(f\"self_games\"):\n",
    "        os.mkdir(f\"self_games\")\n",
    "        \n",
    "    if not os.path.exists(f\"self_games/{model_name}\"):\n",
    "        os.mkdir(f\"self_games/{model_name}\")\n",
    "        \n",
    "    # Add the new generated game, policies, and values to old ones.\n",
    "    if os.path.exists(f'self_games/{model_name}/{nb_simulations}_simu_board_states.pickle'):\n",
    "        \n",
    "        old_board_states, old_policies, old_values, old_nb_games = load_data(model_name, nb_simulations)\n",
    "\n",
    "        board_states = old_board_states + board_states\n",
    "        policies = old_policies + policies\n",
    "        values = old_values + values\n",
    "        nb_games = old_nb_games + nb_games\n",
    "        \n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_board_states.pickle', 'wb') as handle:\n",
    "        pickle.dump(board_states, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_policies.pickle', 'wb') as handle:\n",
    "        pickle.dump(policies, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_values.pickle', 'wb') as handle:\n",
    "        pickle.dump(values, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'self_games/{model_name}/{nb_simulations}_simu_nb_games.pickle', 'wb') as handle:\n",
    "        pickle.dump(nb_games, handle, protocol=pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18439fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_board = Board(deck)\n",
    "root = MonteCarloTreeSearchNode(model, new_board, prior=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54febc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_play(model, \"model1\", root, nb_simulations=200, nb_games=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cafb9a",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a78c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_board_states, old_policies, old_values, old_nb_games = load_data(\"model1\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0882dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_states_2 = np.zeros((len(board_states), 5, 5, 10))\n",
    "policies_2 = np.zeros((len(policies), 5, 5, 52))\n",
    "\n",
    "for i, board in enumerate(board_states):\n",
    "    \n",
    "    board_states_2[i] = board\n",
    "    policies_2[i] = policies[i].reshape((5, 5, 52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(board_states_2, [policies_2, np.array(values)], batch_size=256, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model.history.history).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
